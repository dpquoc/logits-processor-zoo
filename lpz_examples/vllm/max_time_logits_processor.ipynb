{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28ed6952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/projects/logproc_ws/logits-processor-zoo\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5627e226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/envs/logproc/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-05 10:13:49 [__init__.py:244] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-05 10:13:51,942\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-05 10:14:01 [config.py:823] This model supports multiple tasks: {'generate', 'score', 'classify', 'embed', 'reward'}. Defaulting to 'generate'.\n",
      "WARNING 07-05 10:14:01 [config.py:3271] Casting torch.bfloat16 to torch.float16.\n",
      "WARNING 07-05 10:14:02 [cuda.py:91] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
      "INFO 07-05 10:14:02 [llm_engine.py:230] Initializing a V0 LLM engine (v0.9.1) with config: model='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', speculative_config=None, tokenizer='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=16384, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=None, served_model_name=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=False, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":0,\"local_cache_dir\":null}, use_cached_outputs=False, \n",
      "INFO 07-05 10:14:03 [cuda.py:327] Using Flash Attention backend.\n",
      "INFO 07-05 10:14:04 [parallel_state.py:1065] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "INFO 07-05 10:14:04 [model_runner.py:1171] Starting to load model deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B...\n",
      "INFO 07-05 10:14:04 [weight_utils.py:292] Using model weights format ['*.safetensors']\n",
      "INFO 07-05 10:14:04 [weight_utils.py:345] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.55it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-05 10:14:05 [default_loader.py:272] Loading weights took 0.75 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-05 10:14:06 [model_runner.py:1203] Model loading took 3.3461 GiB and 1.098449 seconds\n",
      "INFO 07-05 10:14:06 [worker.py:294] Memory profiling takes 0.48 seconds\n",
      "INFO 07-05 10:14:06 [worker.py:294] the current vLLM instance can use total_gpu_memory (79.19GiB) x gpu_memory_utilization (0.90) = 71.27GiB\n",
      "INFO 07-05 10:14:06 [worker.py:294] model weights take 3.35GiB; non_torch_memory takes 0.16GiB; PyTorch activation peak memory takes 1.46GiB; the rest of the memory reserved for KV Cache is 66.31GiB.\n",
      "INFO 07-05 10:14:06 [executor_base.py:113] # cuda blocks: 155208, # CPU blocks: 9362\n",
      "INFO 07-05 10:14:06 [executor_base.py:118] Maximum concurrency for 16384 tokens per request: 151.57x\n",
      "INFO 07-05 10:14:08 [llm_engine.py:428] init engine (profile, create kv cache, warmup model) took 2.90 seconds\n"
     ]
    }
   ],
   "source": [
    "from lpz_examples.vllm.utils import vLLMRunner\n",
    "from logits_processor_zoo.vllm import MaxTimeLogitsProcessor\n",
    "\n",
    "\n",
    "runner = vLLMRunner(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\")\n",
    "\n",
    "example_prompts = [\n",
    "\"\"\"\n",
    "A farmer has a rectangular field. The length of the field is 20 meters longer than its width. \n",
    "If the perimeter of the field is 200 meters, find the dimensions of the field.\n",
    "\"\"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859aef8d",
   "metadata": {},
   "source": [
    "## Default Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbf4c2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \n",
      "A farmer has a rectangular field. The length of the field is 20 meters longer than its width. \n",
      "If the perimeter of the field is 200 meters, find the dimensions of the field.\n",
      "\n",
      "First, I'll define the width of the field as \\( w \\) meters. Since the length is 20 meters longer than the width, the length will be \\( w + 20 \\) meters.\n",
      "\n",
      "Next, I'll use the formula for the perimeter of a rectangle, which is \\( 2 \\times (\\text{length} + \\text{width}) \\). Plugging in the expressions for length and width, the equation becomes:\n",
      "\\[\n",
      "2(w + (w + 20)) = 200\n",
      "\\]\n",
      "\n",
      "Simplifying the equation:\n",
      "\\[\n",
      "2(2w + 20) = 200 \\\\\n",
      "4w + 40 = 200 \\\\\n",
      "4w = 160 \\\\\n",
      "w = 40\n",
      "\\]\n",
      "\n",
      "Finally, the width is 40 meters, and the length is \\( 40 + 20 = 60 \\) meters.\n",
      "</think>\n",
      "\n",
      "Let's solve the problem step by step.\n",
      "\n",
      "**Given:**\n",
      "- The field is rectangular.\n",
      "- The length is \\( 20 \\) meters longer than the width.\n",
      "- The perimeter of the field is \\( 200 \\) meters.\n",
      "\n",
      "**Let:**\n",
      "- \\( w \\) = width of the field (in meters)\n",
      "- \\( l \\) = length of the field (in meters)\n",
      "\n",
      "**Step 1: Express the Length in Terms of the Width**\n",
      "\n",
      "Since the length is \\( 20 \\) meters longer than the width:\n",
      "\\[\n",
      "l = w + 20\n",
      "\\]\n",
      "\n",
      "**Step 2: Use the Perimeter Formula**\n",
      "\n",
      "The perimeter \\( P \\) of a rectangle is given by:\n",
      "\\[\n",
      "P = 2l + 2w\n",
      "\\]\n",
      "Given that the perimeter is \\( 200 \\) meters:\n",
      "\\[\n",
      "2l + 2w = 200\n",
      "\\]\n",
      "\n",
      "**Step 3: Substitute the Expression for \\( l \\) into the Perimeter Equation**\n",
      "\n",
      "\\[\n",
      "2(w + 20) + 2w = 200\n",
      "\\]\n",
      "\n",
      "**Step 4: Simplify and Solve for \\( w \\)**\n",
      "\n",
      "\\[\n",
      "2w + 40 + 2w = 200 \\\\\n",
      "4w + 40 = 200 \\\\\n",
      "4w = 200 - 40 \\\\\n",
      "4w = 160 \\\\\n",
      "w = \\frac{160}{4} \\\\\n",
      "w = 40 \\text{ meters}\n",
      "\\]\n",
      "\n",
      "**Step 5: Find the Length \\( l \\)**\n",
      "\n",
      "\\[\n",
      "l = w + 20 = 40 + 20 = 60 \\text{ meters}\n",
      "\\]\n",
      "\n",
      "**Final Answer:**\n",
      "\\[\n",
      "\\boxed{\\text{Width: } 40 \\text{ meters}, \\text{ Length: } 60 \\text{ meters}}\n",
      "\\]\n",
      "-----END-----\n",
      "\n",
      "Prompt: Count up to 100.\n",
      "I need to count up from 1 to 100. I'll start at 1 and continue adding one each time until I reach 100. I'll make sure to include every number in between without skipping any. This way, I can ensure that I count up correctly and comprehensively.\n",
      "</think>\n",
      "\n",
      "**Counting Up to 100**\n",
      "\n",
      "To count up from 1 to 100, follow these steps:\n",
      "\n",
      "1. **Start at 1**: Begin your count with the number 1.\n",
      "2. **Add 1 Each Time**: Continue adding 1 to the previous number to get the next number in the sequence.\n",
      "3. **Continue Until 100**: Keep doing this until you reach the number 100.\n",
      "\n",
      "Here is the sequence of numbers from 1 to 100:\n",
      "\n",
      "\\[\n",
      "1, 2, 3, 4, 5, 6, 7, 8, 9, 10, \\ldots, 98, 99, 100\n",
      "\\]\n",
      "\n",
      "By following this method, you will have successfully counted up to 100.\n",
      "-----END-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runner.generate_response(example_prompts, max_tokens=4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bc2f8a",
   "metadata": {},
   "source": [
    "## Interrupt after N seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d74eb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \n",
      "A farmer has a rectangular field. The length of the field is 20 meters longer than its width. \n",
      "If the perimeter of the field is 200 meters, find the dimensions of the field.\n",
      "\n",
      "First, I'll define the width of the field as \\( w \\) meters. Since the length is 20 meters longer than the width, the length will be \\( w + 20 \\) meters.\n",
      "\n",
      "Next, I'll use the formula for the perimeter of a rectangle, which is \\( 2 \\times (\\text{length} + \\text{width}) \\). Plugging in the expressions for length and width, the equation becomes:\n",
      "\\[\n",
      "2(w + (w + 20)) =\n",
      "-----END-----\n",
      "\n",
      "Prompt: Count up to 100.\n",
      "I need to count up from 1 to 100. I'll start at 1 and continue adding one each time until I reach 100. I'll make sure to include every number in between without skipping any. This way, I can ensure that I count up correctly and comprehensively.\n",
      "</think>\n",
      "\n",
      "**Counting Up to 100**\n",
      "\n",
      "To count up from 1 to 100, follow these steps:\n",
      "\n",
      "1. **Start at 1**: Begin your count with the number\n",
      "-----END-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runner.generate_response(example_prompts,\n",
    "                         [MaxTimeLogitsProcessor(runner.tokenizer, \n",
    "                                                complete_sentences=False, \n",
    "                                                max_time=1,\n",
    "                                                )],\n",
    "                        max_tokens=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549f741e",
   "metadata": {},
   "source": [
    "## Combine with TriggerPhrase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40679857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \n",
      "A farmer has a rectangular field. The length of the field is 20 meters longer than its width. \n",
      "If the perimeter of the field is 200 meters, find the dimensions of the field.\n",
      "\n",
      "First, I'll define the width of the field as \\( w \\) meters. Since the length is 20 meters longer than the width, the length will be \\( w + 20 \\) meters.\n",
      "\n",
      "Next, I'll use the formula for the perimeter of a rectangle, which is \\( 2 \\times (\\text{length} + \\text{width}) \\). Plugging in the expressions for length and width, the equation becomes:\n",
      "\\[\n",
      "2(w + (w + 20)) = 200\n",
      "\\]\n",
      "\n",
      "Simplifying the equation:\n",
      "\\[\n",
      "2(2w + 20) = 200 \\\\\n",
      "4w + 40 = 200 \\\\\n",
      "4w = 160 \\\\\n",
      "w = 40\n",
      "\\]\n",
      "\n",
      "Finally, the width is 40 meters, and the length is \\( 40 + 20 = 60 \\) meters.\n",
      "</think>\n",
      "\n",
      "Let's solve the problem step by step.\n",
      "\n",
      "**Given:**\n",
      "- The field is rectangular.\n",
      "- The length is \\( 2<Interruption> The time is over. The final answer is: **Width = 40 meters, Length = 60 meters.\n",
      "-----END-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from logits_processor_zoo.vllm import TriggerPhraseLogitsProcessor\n",
    "\n",
    "hurry_up = TriggerPhraseLogitsProcessor(runner.tokenizer,\n",
    "                                        phrase=\"<Interruption> The time is over. The final answer is:\", \n",
    "                                        trigger_time=2, \n",
    "                                        trigger_count=1, \n",
    "                                        trigger_after=True)\n",
    "max_time = MaxTimeLogitsProcessor(runner.tokenizer,\n",
    "                                 complete_sentences=True,\n",
    "                                 max_time=2.2)\n",
    "\n",
    "runner.generate_response(example_prompts,\n",
    "                         [hurry_up, max_time],\n",
    "                        max_tokens=4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdad362",
   "metadata": {},
   "source": [
    "### Combine with TriggerPhrase: Hurry up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72b70940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Count up to 100.\n",
      "I need to count up from 1 to 100. I'll start at 1 and continue adding one each time until I reach 100. I'll make sure to include every number in between without skipping any. This way, I can ensure that I count up correctly and comprehensively.\n",
      "</think>\n",
      "\n",
      "**Counting Up to 100**\n",
      "\n",
      "To count up from 1 to 100, follow these steps:\n",
      "\n",
      "1. **Start at 1**: Begin your count with the number 1.\n",
      "2. **Add 1 Each Time**: Continue adding 1 to the previous number to get the next number in the sequence.\n",
      "3. **Continue Until 100**: Keep doing this until you reach the number 100.\n",
      "\n",
      "Here is the sequence of numbers from 1 to 100:\n",
      "\n",
      "\\[\n",
      "1, 2, 3, 4, 5, 6, 7, 8, 9, 10, \\ldots, 98, 99, 100\n",
      "\\]\n",
      "\n",
      "By following this method, you will have successfully counted up to 100.\n",
      "-----END-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_prompts = [\n",
    "    \"\"\"Count up to 100.\"\"\"\n",
    "]\n",
    "\n",
    "runner.generate_response(example_prompts,\n",
    "                        max_tokens=4096)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dfff28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Count up to 100.\n",
      "I need to count up from 1 to 100. I'll start at 1 and continue adding one each time until I reach 100. I'll make sure to include every number in between without skipping any. This way, I can ensure that I<Interruption> Hurry up! The time is almost over. Stop thinking and go straight to a short answer. <Interruption> The count from 1 to 100 is straightforward. I'll list each number sequentially, making sure to include every integer from 1 up to 100. This will provide a clear and complete sequence of numbers in the specified range. </Interruption>\n",
      "</think>\n",
      "\n",
      "**Counting from 1 to 100**\n",
      "\n",
      "Here is the sequence of numbers from 1 to 100:\n",
      "\n",
      "\\[\n",
      "1, 2, 3, \\ldots, 98, 99, 100\n",
      "\\]\n",
      "\n",
      "This is a straightforward count where each number is incremented by 1 from the previous number, starting at 1 and ending at 100.\n",
      "-----END-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "example_prompts = [\n",
    "    \"\"\"Count up to 100.\"\"\"\n",
    "]\n",
    "\n",
    "hurry_up = TriggerPhraseLogitsProcessor(runner.tokenizer,\n",
    "                                        phrase=\"<Interruption> Hurry up! The time is almost over. Stop thinking and go straight to a short answer. <Interruption>\", \n",
    "                                        trigger_time=0.5, \n",
    "                                        trigger_count=1, \n",
    "                                        trigger_after=True)\n",
    "max_time = MaxTimeLogitsProcessor(runner.tokenizer,\n",
    "                                 complete_sentences=True,\n",
    "                                 max_time=3)\n",
    "\n",
    "runner.generate_response(example_prompts,\n",
    "                         [hurry_up, max_time],\n",
    "                        max_tokens=4096)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logproc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
